{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11222601,"sourceType":"datasetVersion","datasetId":7008241}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom imgaug import augmenters as iaa\nfrom tqdm import tqdm\nimport shutil","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-31T08:19:36.364048Z","iopub.execute_input":"2025-03-31T08:19:36.364413Z","iopub.status.idle":"2025-03-31T08:19:36.368917Z","shell.execute_reply.started":"2025-03-31T08:19:36.364382Z","shell.execute_reply":"2025-03-31T08:19:36.367985Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Set paths using your exact structure\ninput_path = \"/kaggle/input/labeled-faces-in-the-wild/LFW_Dataset_11_15/LFW_Dataset_11_15\"\noutput_path = \"/kaggle/working/LFW_Processed\"\ntrain_path = os.path.join(output_path, \"training_data\")\ntest_path = os.path.join(output_path, \"testing_data\")\n\n# Verify input path exists\nif not os.path.exists(input_path):\n    print(\"\\nError: Could not find dataset at:\", input_path)\n    print(\"\\nTrying to locate your dataset...\")\n    \n    # Check possible locations\n    base_path = \"/kaggle/input\"\n    if os.path.exists(base_path):\n        print(\"\\nContents of /kaggle/input:\")\n        print(os.listdir(base_path))\n        \n        if 'labeled-faces-in-the-wild' in os.listdir(base_path):\n            wild_path = os.path.join(base_path, 'labeled-faces-in-the-wild')\n            print(\"\\nContents of labeled-faces-in-the-wild:\")\n            print(os.listdir(wild_path))\n            \n            if 'LFW_Dataset_11_15' in os.listdir(wild_path):\n                dataset_path = os.path.join(wild_path, 'LFW_Dataset_11_15')\n                print(\"\\nContents of LFW_Dataset_11_15:\")\n                print(os.listdir(dataset_path))\n    \n    raise FileNotFoundError(f\"Could not find dataset at: {input_path}\\nPlease verify the path and try again.\")\n\nprint(f\"\\nDataset found at: {input_path}\")\nprint(\"Processing...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T08:17:28.879382Z","iopub.execute_input":"2025-03-31T08:17:28.879794Z","iopub.status.idle":"2025-03-31T08:17:28.891077Z","shell.execute_reply.started":"2025-03-31T08:17:28.879762Z","shell.execute_reply":"2025-03-31T08:17:28.890198Z"}},"outputs":[{"name":"stdout","text":"\nDataset found at: /kaggle/input/labeled-faces-in-the-wild/LFW_Dataset_11_15/LFW_Dataset_11_15\nProcessing...\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Create output directories\nos.makedirs(train_path, exist_ok=True)\nos.makedirs(test_path, exist_ok=True)\n\n# Augmentation setup\naugmentation = iaa.Sequential([\n    iaa.Fliplr(0.5),  # horizontal flips\n    iaa.Affine(\n        rotate=(-20, 20),\n        scale=(0.8, 1.2),\n        translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}\n    ),\n    iaa.GaussianBlur(sigma=(0, 1.0)),\n    iaa.LinearContrast((0.8, 1.2)),\n    iaa.AdditiveGaussianNoise(scale=(0, 0.05*255))\n])\n\ndef augment_image(image, num_augmentations):\n    \"\"\"Generate augmented versions of an image\"\"\"\n    augmented_images = []\n    for _ in range(num_augmentations):\n        augmented = augmentation(image=image)\n        augmented_images.append(augmented)\n    return augmented_images\n\ndef process_person(person_dir, person_name):\n    \"\"\"Process images for one person\"\"\"\n    image_files = [f for f in os.listdir(person_dir) \n                  if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n    original_images = []\n    \n    for img_file in image_files:\n        img_path = os.path.join(person_dir, img_file)\n        img = cv2.imread(img_path)\n        if img is not None:\n            original_images.append(img)\n    \n    num_images = len(original_images)\n    \n    # Augment if needed to reach 15 images\n    if num_images < 15:\n        needed = 15 - num_images\n        augmented_images = []\n        \n        # Distribute augmentations across original images\n        per_image = max(1, needed // num_images)\n        remainder = needed % num_images\n        \n        for i, img in enumerate(original_images):\n            to_generate = per_image + (1 if i < remainder else 0)\n            if to_generate > 0:\n                augmented_images.extend(augment_image(img, to_generate))\n        \n        all_images = original_images + augmented_images\n    else:\n        all_images = original_images[:15]  # Take first 15 if more available\n    \n    # Shuffle and split\n    np.random.shuffle(all_images)\n    train_images = all_images[:10]\n    test_images = all_images[10:15]\n    \n    return train_images, test_images\n\ndef save_images(images, output_dir, person_name, prefix):\n    \"\"\"Save images to appropriate directory\"\"\"\n    person_output_dir = os.path.join(output_dir, person_name)\n    os.makedirs(person_output_dir, exist_ok=True)\n    \n    for i, img in enumerate(images):\n        output_path = os.path.join(person_output_dir, f\"{prefix}_{i+1:02d}.jpg\")\n        cv2.imwrite(output_path, img)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T08:17:31.164956Z","iopub.execute_input":"2025-03-31T08:17:31.165325Z","iopub.status.idle":"2025-03-31T08:17:31.180316Z","shell.execute_reply.started":"2025-03-31T08:17:31.165294Z","shell.execute_reply":"2025-03-31T08:17:31.179244Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Get all person folders\nperson_folders = [d for d in os.listdir(input_path) \n                 if os.path.isdir(os.path.join(input_path, d))]\n\nprint(f\"\\nFound {len(person_folders)} persons to process\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T08:17:33.350565Z","iopub.execute_input":"2025-03-31T08:17:33.350921Z","iopub.status.idle":"2025-03-31T08:17:33.415820Z","shell.execute_reply.started":"2025-03-31T08:17:33.350876Z","shell.execute_reply":"2025-03-31T08:17:33.414906Z"}},"outputs":[{"name":"stdout","text":"\nFound 58 persons to process\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Process each person\nfor person in tqdm(person_folders, desc=\"Processing persons\"):\n    person_dir = os.path.join(input_path, person)\n    train_imgs, test_imgs = process_person(person_dir, person)\n    \n    # Save images\n    save_images(train_imgs, train_path, person, \"train\")\n    save_images(test_imgs, test_path, person, \"test\")\n\nprint(\"\\nProcessing complete!\")\nprint(f\"Training data saved to: {train_path}\")\nprint(f\"Testing data saved to: {test_path}\")\nprint(f\"\\nTotal persons processed: {len(person_folders)}\")\nprint(f\"Training images per person: 10\")\nprint(f\"Testing images per person: 5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T08:17:36.696166Z","iopub.execute_input":"2025-03-31T08:17:36.696534Z","iopub.status.idle":"2025-03-31T08:17:44.498574Z","shell.execute_reply.started":"2025-03-31T08:17:36.696502Z","shell.execute_reply":"2025-03-31T08:17:44.497102Z"}},"outputs":[{"name":"stderr","text":"Processing persons: 100%|██████████| 58/58 [00:07<00:00,  7.45it/s]","output_type":"stream"},{"name":"stdout","text":"\nProcessing complete!\nTraining data saved to: /kaggle/working/LFW_Processed/training_data\nTesting data saved to: /kaggle/working/LFW_Processed/testing_data\n\nTotal persons processed: 58\nTraining images per person: 10\nTesting images per person: 5\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"folder_path = \"/kaggle/working/LFW_Processed\"  # Change this to your folder name\nzip_file = \"LFW_Processed.zip\"  # Output zip file\n\nshutil.make_archive(zip_file.replace(\".zip\", \"\"), 'zip', folder_path)\nprint(f\"Zipped {folder_path} as {zip_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T08:19:53.015263Z","iopub.execute_input":"2025-03-31T08:19:53.015641Z","iopub.status.idle":"2025-03-31T08:19:53.756346Z","shell.execute_reply.started":"2025-03-31T08:19:53.015606Z","shell.execute_reply":"2025-03-31T08:19:53.755493Z"}},"outputs":[{"name":"stdout","text":"Zipped /kaggle/working/LFW_Processed as LFW_Processed.zip\n","output_type":"stream"}],"execution_count":8}]}